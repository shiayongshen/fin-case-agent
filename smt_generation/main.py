import json
import pandas as pd
from pathlib import Path
import time
from datetime import datetime

from config import llm_config
from agents.orchestrator import build_team
from agents.prompt import COMPLETION_PROMPT_TEMPLATE
from core.repair_pipeline import repair_loop
import os
import sys
# æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘ï¼Œä»¥æ”¯æŒç›¸å°å°å…¥
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from find_optimize_result.json2z3 import declare_vars, build_expr
from concurrent.futures import ThreadPoolExecutor, as_completed
import io

from utils import (
    get_reply_with_tokens,
    ensure_json_valid,
    sync_types_constraints_and_varspecs,
    check_constraints_parseable,
    check_constraints_consistency,
    repair_sat_to_unsat,
    check_case_law_hard,
    z3_optimize_case,
    calculate_cost,
    extract_all_vars,
    check_constraints_parseable,
    repair_loop_with_rounds,
    auto_fix_constraints,
    consistency_check_with_repair,
    add_penalty_meta,
    diagnose_constraints,
    safe_json_loads,
    clean_json_response,
    repair_case_law_constraints,
    export_to_smt2,
    validate_and_fix_facts
)

# ä¿®æ­£è·¯å¾‘ç‚ºçµ•å°è·¯å¾‘
current_dir = Path(__file__).parent
# å„ªå…ˆæŸ¥æ‰¾æœ¬ç›®éŒ„ä¸‹çš„ dataset è³‡æ–™å¤¾ï¼Œå¦å‰‡ä½¿ç”¨æ ¹ç›®éŒ„
DATA_CANDIDATES = [
    current_dir / "dataset" / "updated_processed_cases.csv",
    current_dir.parent / "updated_processed_cases.csv",
    current_dir.parent / "data_preprocess" / "updated_processed_cases.csv",
]

DATA = None
for candidate in DATA_CANDIDATES:
    if candidate.exists():
        DATA = candidate
        print(f"âœ… Found data file: {DATA}")
        break

if DATA is None:
    raise FileNotFoundError(f"âŒ Could not find updated_processed_cases.csv in any of: {DATA_CANDIDATES}")

OUT = current_dir / "outputs"
OUT.mkdir(parents=True, exist_ok=True)


class PipelineStats:
    """ç´€éŒ„ pipeline åŸ·è¡Œçµ±è¨ˆ"""
    def __init__(self, case_id):
        self.case_id = case_id
        self.start_time = time.time()
        self.agent_calls = []  # ç´€éŒ„æ¯æ¬¡ agent å‘¼å«
        self.repair_attempts = 0
        self.success = False
        self.error_message = None
        self.fix_logs = []
        
        # ğŸ”‘ æª¢æŸ¥é»ç‹€æ…‹
        self.checkpoints = {
            "step1_law_parser": None,
            "step2_completion": None,
            "step3_json_valid": None,
            "step4_varspec": None,
            "step5_constraints_parseable": None,
            "step5_repair_needed": False,
            "step5_repair_success": None,
            "step6_consistency_check": None,
            "step6_repair_success": None,  # æ–°å¢ï¼šStep 6 ä¿®å¾©æˆåŠŸæª¢æŸ¥é»
            "step7_case_mapper": None,
            "step7_facts_validation": None,
            "step7_z3_validation": None,
            "step8_case_law_check": None,
            "step8_repair_success": None,  # æ–°å¢ï¼šStep 8 ä¿®å¾©æˆåŠŸæª¢æŸ¥é»
            "step8_violation_detected": None,
            "step9_z3_optimize": None
        }
        
    def log_checkpoint(self, checkpoint_name, passed, details=None):
        """
        ç´€éŒ„æª¢æŸ¥é»ç‹€æ…‹
        
        Args:
            checkpoint_name: æª¢æŸ¥é»åç¨±
            passed: æ˜¯å¦é€šé (True/False/None)
            details: é¡å¤–è³‡è¨Šï¼ˆå¯é¸ï¼‰
        """
        self.checkpoints[checkpoint_name] = {
            "passed": passed,
            "details": details,
            "timestamp": time.time() - self.start_time
        }
        
        # å°å‡ºç‹€æ…‹
        status = "âœ…" if passed else "âŒ" if passed is False else "âš ï¸"
        detail_str = f" ({details})" if details else ""
        print(f"{status} Checkpoint [{checkpoint_name}]: {'PASS' if passed else 'FAIL' if passed is False else 'SKIP'}{detail_str}")
        
    def log_agent_call(self, agent_name, input_tokens, output_tokens, elapsed_time):
        """ç´€éŒ„å–®æ¬¡ agent å‘¼å«"""
        cost = calculate_cost(input_tokens, output_tokens)
        self.agent_calls.append({
            "agent": agent_name,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "elapsed_time": elapsed_time,
            "cost": cost
        })
    def log_fix(self, constraint_id, rule, before, after):
        """è¨˜éŒ„å–®æ¬¡è‡ªå‹•ä¿®å¾©å‹•ä½œ"""
        self.fix_logs.append({
            "id": constraint_id,
            "rule": rule,
            "before": before,
            "after": after,
            "timestamp": round(time.time() - self.start_time, 2)
        })
        
    def increment_repair(self):
        """å¢åŠ ä¿®å¾©æ¬¡æ•¸"""
        self.repair_attempts += 1
    
    def mark_success(self):
        """æ¨™è¨˜æˆåŠŸ"""
        self.success = True
    
    def mark_failure(self, error):
        """æ¨™è¨˜å¤±æ•—"""
        self.success = False
        self.error_message = str(error)
    
    def get_total_time(self):
        """å–å¾—ç¸½åŸ·è¡Œæ™‚é–“"""
        return time.time() - self.start_time
    
    def get_total_tokens(self):
        """å–å¾—ç¸½ token æ•¸"""
        total_input = sum(call["input_tokens"] for call in self.agent_calls)
        total_output = sum(call["output_tokens"] for call in self.agent_calls)
        return total_input, total_output
    
    def get_total_cost(self):
        """å–å¾—ç¸½èŠ±è²»"""
        return sum(call["cost"] for call in self.agent_calls)
    
    def get_checkpoint_summary(self):
        """å–å¾—æª¢æŸ¥é»æ‘˜è¦ï¼ˆç”¨æ–¼ Excelï¼‰"""
        summary = {}
        for name, data in self.checkpoints.items():
            if data is None:
                summary[name] = "NOT_RUN"
            elif isinstance(data, bool):
                summary[name] = "PASS" if data else "FAIL"
            else:
                summary[name] = "PASS" if data.get("passed") else "FAIL" if data.get("passed") is False else "SKIP"
        return summary
    
    def to_summary_dict(self):
        """è½‰ç‚ºæ‘˜è¦å­—å…¸ï¼ˆç”¨æ–¼ Excelï¼‰"""
        total_input, total_output = self.get_total_tokens()
        base_summary = {
            "case_id": self.case_id,
            "success": self.success,
            "error_message": self.error_message,
            "total_time_sec": round(self.get_total_time(), 2),
            "repair_attempts": self.repair_attempts,
            "total_agent_calls": len(self.agent_calls),
            "total_input_tokens": total_input,
            "total_output_tokens": total_output,
            "total_tokens": total_input + total_output,
            "total_cost_usd": round(self.get_total_cost(), 6),
            "timestamp": datetime.now().isoformat()
        }
        
        # ğŸ”‘ åŠ å…¥æª¢æŸ¥é»ç‹€æ…‹
        checkpoint_summary = self.get_checkpoint_summary()
        base_summary.update(checkpoint_summary)
        
        return base_summary
    
    def to_detailed_dict(self):
        """è½‰ç‚ºè©³ç´°å­—å…¸ï¼ˆåŒ…å«æ¯æ¬¡ agent å‘¼å«ï¼‰"""
        summary = self.to_summary_dict()
        summary["agent_calls"] = self.agent_calls
        summary["checkpoints_detail"] = self.checkpoints
        summary["fix_logs"] = self.fix_logs
        return summary


def save_results(case_id, constraints, varspecs, facts, stats):
    """å„²å­˜çµæœåˆ°ä¸‰å€‹ JSON æª”æ¡ˆ"""
    # 1. Constraints
    constraint_path = OUT / f"{case_id}.constraint_spec.json"
    constraint_path.write_text(
        json.dumps(constraints, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )
    
    # 2. VarSpecs
    varspec_path = OUT / f"{case_id}.varspecs.json"
    varspec_path.write_text(
        json.dumps(varspecs, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )
    
    # 3. Facts
    facts_path = OUT / f"{case_id}.facts.json"
    facts_path.write_text(
        json.dumps(facts, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )
    
    # 4. çµ±è¨ˆè³‡æ–™ï¼ˆè©³ç´°ç‰ˆï¼‰
    stats_path = OUT / f"{case_id}.stats.json"
    stats_path.write_text(
        json.dumps(stats.to_detailed_dict(), ensure_ascii=False, indent=2),
        encoding="utf-8"
    )
    
    print(f"âœ… Saved results to:")
    print(f"   - {constraint_path}")
    print(f"   - {varspec_path}")
    print(f"   - {facts_path}")
    print(f"   - {stats_path}")


def run_pipeline(team, case_id, case_text, statute_text):
    """
    åŸ·è¡Œå®Œæ•´æµç¨‹åœ–çš„ pipeline
    """
    stats = PipelineStats(case_id)
    log_buffer = io.StringIO()
    old_stdout = sys.stdout
    sys.stdout = log_buffer
    try:
        # === Step 1: Law Parser ===
        print("\n" + "="*60)
        print("Step 1: Law Parser")
        print("="*60)
        parser_prompt = f"ã€ç›¸é—œæ³•æ¢ã€‘\n{statute_text}\nâ€”â€”è«‹è¼¸å‡º ConstraintSpec[]ï¼ˆJSON é™£åˆ—ï¼‰ã€‚"
        parser_messages = [{"role": "user", "content": parser_prompt}]
        
        start = time.time()
        parser_reply, input_tokens, output_tokens = get_reply_with_tokens(team["parser"], parser_messages)
        elapsed = time.time() - start
        stats.log_agent_call("parser", input_tokens, output_tokens, elapsed)
        stats.log_checkpoint("step1_law_parser", True, f"{len(parser_reply)} chars")

        # === Step 2: Completion (è£œå®Œ) ===
        print("\n" + "="*60)
        print("Step 2: Law Completion")
        print("="*60)
        completion_prompt = COMPLETION_PROMPT_TEMPLATE.format(
            statute_text=statute_text,
            existing_constraints=parser_reply
        )
        parser_messages.append({"role": "user", "content": completion_prompt})
        
        start = time.time()
        completion_reply, input_tokens, output_tokens = get_reply_with_tokens(team["parser"], parser_messages)
        elapsed = time.time() - start
        stats.log_agent_call("parser_completion", input_tokens, output_tokens, elapsed)
        stats.log_checkpoint("step2_completion", True, f"{len(completion_reply)} chars")

        # === Step 3: JSON Valid? ===
        print("\n" + "="*60)
        print("Step 3: Ensure JSON Valid")
        print("="*60)
        try:
            constraints = ensure_json_valid(team, parser_reply)
            stats.log_checkpoint("step3_json_valid", True, f"{len(constraints)} constraints")
        except Exception as e:
            stats.log_checkpoint("step3_json_valid", False, str(e))
            raise

        # === Step 4: VarSpec ===
        print("\n" + "="*60)
        print("Step 4: VarSpec Extraction")
        print("="*60)
        used_vars = extract_all_vars(constraints)
        varspec_prompt = f"ã€éœ€ç”¨åˆ°çš„è®Šæ•¸ã€‘\n{', '.join(used_vars)}\nâ€”â€”è«‹è¼¸å‡º varspecsï¼ˆJSON é™£åˆ—ï¼‰ã€‚"
        varspec_messages = [{"role": "user", "content": varspec_prompt}]
        
        start = time.time()
        varspec_reply, input_tokens, output_tokens = get_reply_with_tokens(team["varspec"], varspec_messages)
        elapsed = time.time() - start
        stats.log_agent_call("varspec", input_tokens, output_tokens, elapsed)
        
        try:
            varspec_reply = clean_json_response(varspec_reply)
            varspecs = json.loads(varspec_reply)
            stats.log_checkpoint("step4_varspec", True, f"{len(varspecs)} varspecs")
        except Exception as e:
            stats.log_checkpoint("step4_varspec", False, str(e))
            raise

        # å®£å‘Š Z3 è®Šæ•¸
        z3_vars = declare_vars(varspecs)
        constraints, varspecs = auto_fix_constraints(constraints, varspecs)
        constraints, varspecs = sync_types_constraints_and_varspecs(constraints, varspecs, stats)
        # print("\n" + "="*60)
        # print(constraints)
        # print("="*60)
        # print(varspecs)
        z3_vars = declare_vars(varspecs)
        # constraints = fix_case_types_by_varspecs(constraints, varspecs, stats)
        # print(constraints)
        # === Step 5: Constraints å¯ parse? ===
        print("\n" + "="*60)
        print("Step 5: Check Constraints Parseable")
        print("="*60)
        ok, err = check_constraints_parseable(constraints, z3_vars, build_expr)
        
        if not ok:
            stats.log_checkpoint("step5_constraints_parseable", False, err)
            stats.checkpoints["step5_repair_needed"] = True
            
            problems = diagnose_constraints(constraints, z3_vars, build_expr)
            print(f"âš ï¸ Found {len(problems)} problematic constraints:")
            for p in problems:
                print(f"  - [{p['id']}] {p['error']}")
            
            print(f"âš ï¸ Constraints parse failed: {err}")
            stats.increment_repair()
            
            # ğŸ”‘ ä¿®å¾©æ™‚ä¹Ÿè¦ç´€éŒ„ agent å‘¼å«
            constraints, varspecs, ok, rounds, last_err = repair_loop_with_rounds_with_stats(
                team, constraints, varspecs, build_expr, z3_vars, stats, max_rounds=3
            )
            
            if ok:
                print(f"âœ… Repair success after {rounds} round(s)")
                stats.log_checkpoint("step5_repair_success", True, f"{rounds} rounds")
            else:
                stats.log_checkpoint("step5_repair_success", False, last_err)
                raise RuntimeError(f"âŒ ä¿®å¾©å¤±æ•—ï¼Œæœ€å¾ŒéŒ¯èª¤: {last_err}")
        else:
            print("âœ… Constraints successfully parsed into Z3 expressions")
            stats.log_checkpoint("step5_constraints_parseable", True, f"{len(constraints)} constraints")

        # === Step 6: Constraints Consistency ===
        print("\n" + "="*60)
        print("Step 6: Constraints Consistency")
        print("="*60)
        constraints, ok, result, info = consistency_check_with_repair(team, constraints, z3_vars, build_expr, stats=stats)  # æ–°å¢ stats åƒæ•¸

        if not ok:
            print(f"âš ï¸ Still inconsistent after repair: {info}")
            stats.log_checkpoint("step6_consistency_check", False, info)
            stats.log_checkpoint("step6_repair_success", False, "Repair failed")  # æ–°å¢

        else:
            print("âœ… Constraints passed consistency check")
            stats.log_checkpoint("step6_consistency_check", True, result)
            stats.log_checkpoint("step6_repair_success", True, "Repair successful")  # æ–°å¢


            # ä¿®å¾©å¾Œé‡æ–°ç”Ÿæˆ VarSpec
            used_vars = extract_all_vars(constraints)
            varspec_prompt = f"ã€éœ€ç”¨åˆ°çš„è®Šæ•¸ã€‘\n{', '.join(used_vars)}\nâ€”â€”è«‹è¼¸å‡º varspecsï¼ˆJSON é™£åˆ—ï¼‰ã€‚"
            varspec_messages = [{"role": "user", "content": varspec_prompt}]
            
            start = time.time()
            varspec_reply, input_tokens, output_tokens = get_reply_with_tokens(team["varspec"], varspec_messages)
            elapsed = time.time() - start
            stats.log_agent_call("varspec_post_repair", input_tokens, output_tokens, elapsed)
            
            varspecs = json.loads(varspec_reply)
            z3_vars = declare_vars(varspecs)

        # === Step 7: Case Mapper ===
        print("\n" + "="*60)
        print("Step 7: Case Mapper")
        print("="*60)
        mapper_prompt = (
            f"ã€æ³•å¾‹æ¡ˆä¾‹ã€‘\n{case_text}\n\n"
            f"ã€ç›¸é—œ Constraintsã€‘\n{json.dumps(constraints, ensure_ascii=False, indent=2)}\n\n"
            f"ã€éœ€ç”¨åˆ°çš„è®Šæ•¸èˆ‡å‹åˆ¥ã€‘\n{json.dumps(varspecs, ensure_ascii=False, indent=2)}\n\n"
            "â€”â€”è«‹æ ¹æ“šæ¡ˆä¾‹å…§å®¹ï¼Œè¼¸å‡º factsï¼ˆJSON ç‰©ä»¶ï¼‰ã€‚\n\n"
            "âš ï¸ **é‡è¦è¦å‰‡**ï¼š\n"
            "1. **ç¦æ­¢ä½¿ç”¨ null/None**\n"
            "2. **åªèƒ½ä½¿ç”¨ VarSpec ä¸­çš„è®Šæ•¸**\n"
            "3. è‹¥æŸäº›è®Šæ•¸å¯å¾å…¶ä»–è®Šæ•¸æ¨å°ï¼Œè«‹åƒ…è¨­å®šåŸºç¤è®Šæ•¸\n"
            "4. **å› ç‚ºé€™æ˜¯é•è¦æ¡ˆä¾‹ï¼Œè«‹è¨­å®š facts ä½¿ä¹‹é•åè‡³å°‘ä¸€å€‹ constraint**ï¼ˆç¢ºä¿æ•´é«”æª¢æŸ¥ç‚º UNSATï¼‰\n\n"
            "5. è‹¥æ¶‰åŠåˆ°è¨ˆç®—çš„éƒ¨åˆ†ï¼Œè«‹ç¢ºä¿å–®ä½ä¸€è‡´ä»¥å…å‡ºç¾è¨ˆç®—éŒ¯èª¤\n"
            "5. åƒ…è¼¸å‡º JSON ç‰©ä»¶ï¼Œä¸è¦åŒ…å« markdown æ¨™è¨˜ã€è¨»è§£\n\n"
            "ç¯„ä¾‹ï¼ˆä¸è¦åŒ…å«è¨»è§£ï¼‰ï¼š\n"
            "```json\n"
            "{\n"
            '  "stop_profit_distribution": false,\n'
            '  "capital_ratio": 0.0,\n'
            '  "violation_count": 0\n'
            "}\n"
            "```"
        )
        mapper_messages = [{"role": "user", "content": mapper_prompt}]
        
        start = time.time()
        mapper_reply, input_tokens, output_tokens = get_reply_with_tokens(team["mapper"], mapper_messages)
        elapsed = time.time() - start
        stats.log_agent_call("mapper", input_tokens, output_tokens, elapsed)
        
        try:
            mapper_reply = clean_json_response(mapper_reply)
            
            # ğŸ”‘ ç§»é™¤ JSON ä¸­çš„è¨»è§£ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
            import re
            mapper_reply = re.sub(r'//.*', '', mapper_reply)  # ç§»é™¤å–®è¡Œè¨»è§£
            mapper_reply = re.sub(r'/\*.*?\*/', '', mapper_reply, flags=re.DOTALL)  # ç§»é™¤å¤šè¡Œè¨»è§£
            
            facts = json.loads(mapper_reply)
            if "facts" in facts:
                facts = facts["facts"]
            
            stats.log_checkpoint("step7_case_mapper", True, f"{len(facts)} facts")
        except Exception as e:
            stats.log_checkpoint("step7_case_mapper", False, str(e))
            raise
        
        # ğŸ”‘ é©—è­‰ä¸¦ä¿®å¾© facts
        # === Step 7.1: Validate and Fix Facts ===
        # print("\n" + "="*60)
        # print("Step 7.1: Validate and Fix Facts")
        # print("="*60)
        # try:
        #     facts, fix_issues = validate_and_fix_facts(facts, varspecs)
        #     stats.log_checkpoint("step7_facts_validation", True, f"{len(fix_issues)} fixes" if fix_issues else "no issues")
        # except Exception as e:
        #     stats.log_checkpoint("step7_facts_validation", False, str(e))
        #     raise

        # === Step 7.2: é©—è­‰ facts æ˜¯å¦å¯ç”¨æ–¼ Z3 ===
        print("\n" + "="*60)
        print("Step 7.2: Test Facts with Z3")
        print("="*60)
        
        # ğŸ”‘ éæ¿¾ factsï¼Œåªä¿ç•™åœ¨ z3_vars ä¸­çš„è®Šæ•¸
        z3_var_names = set(z3_vars.keys())
        filtered_facts = {k: v for k, v in facts.items() if k in z3_var_names}
        if len(filtered_facts) < len(facts):
            removed_keys = set(facts.keys()) - set(filtered_facts.keys())
            print(f"âš ï¸ Removed invalid keys from facts: {removed_keys}")
            facts = filtered_facts 
        try:
            from find_optimize_result.json2z3 import build_facts_dict
            test_constraints = build_facts_dict(facts, z3_vars)
            print("âœ… Facts validated with Z3")
            stats.log_checkpoint("step7_z3_validation", True, f"{len(test_constraints)} constraints")
        except Exception as e:
            print(f"âŒ Facts validation failed: {e}")
            # ğŸ”‘ å˜—è©¦ä¿®å¾© facts
            print("\n" + "="*60)
            print("Step 7.2.1: Repair Facts")
            print("="*60)
            try:
                old_facts = facts.copy()  # è¨˜éŒ„ä¿®å¾©å‰çš„ facts
                # é‡æ–°å‘¼å« mapper agent ç”Ÿæˆ facts
                mapper_prompt_repair = (
                    f"ã€æ³•å¾‹æ¡ˆä¾‹ã€‘\n{case_text}\n\n"
                    f"ã€ç›¸é—œ Constraintsã€‘\n{json.dumps(constraints, ensure_ascii=False, indent=2)}\n\n"
                    f"ã€éœ€ç”¨åˆ°çš„è®Šæ•¸èˆ‡å‹åˆ¥ã€‘\n{json.dumps(varspecs, ensure_ascii=False, indent=2)}\n\n"
                    "â€”â€”è«‹æ ¹æ“šæ¡ˆä¾‹å…§å®¹ï¼Œè¼¸å‡º factsï¼ˆJSON ç‰©ä»¶ï¼‰ã€‚\n\n"
                    "âš ï¸ **é‡è¦è¦å‰‡**ï¼š\n"
                    "1. **ç¦æ­¢ä½¿ç”¨ null/None**\n"
                    "2. **åªèƒ½ä½¿ç”¨ VarSpec ä¸­çš„è®Šæ•¸**\n"
                    "3. è‹¥æŸäº›è®Šæ•¸å¯å¾å…¶ä»–è®Šæ•¸æ¨å°ï¼Œè«‹åƒ…è¨­å®šåŸºç¤è®Šæ•¸\n"
                    "4. **å› ç‚ºé€™æ˜¯é•è¦æ¡ˆä¾‹ï¼Œè«‹è¨­å®š facts ä½¿ä¹‹é•åè‡³å°‘ä¸€å€‹ constraint**ï¼ˆç¢ºä¿æ•´é«”æª¢æŸ¥ç‚º UNSATï¼‰\n\n"
                    "5. è‹¥æ¶‰åŠåˆ°è¨ˆç®—çš„éƒ¨åˆ†ï¼Œè«‹ç¢ºä¿å–®ä½ä¸€è‡´ä»¥å…å‡ºç¾è¨ˆç®—éŒ¯èª¤\n"
                    "6. åƒ…è¼¸å‡º JSON ç‰©ä»¶ï¼Œä¸è¦åŒ…å« markdown æ¨™è¨˜ã€è¨»è§£\n\n"
                    f"âš ï¸ **ä¿®å¾©æç¤º**ï¼šä¹‹å‰çš„ facts é©—è­‰å¤±æ•— ({str(e)})ï¼Œè«‹ä¿®æ­£ä¸¦é‡æ–°è¼¸å‡ºã€‚\n\n"
                    "ç¯„ä¾‹ï¼ˆä¸è¦åŒ…å«è¨»è§£ï¼‰ï¼š\n"
                    "```json\n"
                    "{\n"
                    '  "stop_profit_distribution": false,\n'
                    '  "capital_ratio": 0.0,\n'
                    '  "violation_count": 0\n'
                    "}\n"
                    "```"
                )
                mapper_messages_repair = [{"role": "user", "content": mapper_prompt_repair}]
                
                start = time.time()
                mapper_reply_repair, input_tokens, output_tokens = get_reply_with_tokens(team["mapper"], mapper_messages_repair)
                elapsed = time.time() - start
                stats.log_agent_call("mapper_repair", input_tokens, output_tokens, elapsed)
                
                mapper_reply_repair = clean_json_response(mapper_reply_repair)
                import re
                mapper_reply_repair = re.sub(r'//.*', '', mapper_reply_repair)
                mapper_reply_repair = re.sub(r'/\*.*?\*/', '', mapper_reply_repair, flags=re.DOTALL)
                
                facts = json.loads(mapper_reply_repair)
                if "facts" in facts:
                    facts = facts["facts"]
                
                # é‡æ–°éæ¿¾
                filtered_facts = {k: v for k, v in facts.items() if k in z3_var_names}
                if len(filtered_facts) < len(facts):
                    removed_keys = set(facts.keys()) - set(filtered_facts.keys())
                    print(f"âš ï¸ Removed invalid keys from facts after repair: {removed_keys}")
                    facts = filtered_facts
                
                # é‡æ–°é©—è­‰
                test_constraints = build_facts_dict(facts, z3_vars)
                print("âœ… Facts repaired and validated with Z3")
                stats.log_checkpoint("step7_z3_validation", True, f"{len(test_constraints)} constraints (repaired)")
                stats.log_fix("facts_repair", "Regenerate facts", old_facts, facts)  # è¨˜éŒ„ä¿®å¾© log
            except Exception as repair_e:
                print(f"âŒ Facts repair failed: {repair_e}")
                stats.log_checkpoint("step7_z3_validation", False, f"Repair failed: {str(repair_e)}")
                raise
        
        # === Step 8: Case+Law Hard Check ===  
        print("\n" + "="*60)
        print("Step 8: Case+Law Hard Check")
        print("="*60)
        sat_result, info = check_case_law_hard(constraints, facts, z3_vars, build_expr)

        # ğŸ”‘ Step 8.1: å¦‚æœæª¢æŸ¥å¤±æ•—æˆ– SATï¼ˆä½†æœŸæœ› UNSATï¼‰ï¼Œå˜—è©¦ä¿®å¾©
        if sat_result == "ERROR":
            print(f"âš ï¸ Case+Law check error: {info}")
            stats.log_checkpoint("step8_case_law_check", False, str(info))
            
            # å˜—è©¦ä¿®å¾©æœ‰å•é¡Œçš„ constraints
            print("\n" + "="*60)
            print("Step 8.1: Repair Problematic Constraints")
            print("="*60)
            
            constraints, repair_success = repair_case_law_constraints(
                team=team,
                constraints=constraints,
                facts=facts,
                z3_vars=z3_vars,
                build_expr=build_expr,
                error_info=info,
                stats=stats
            )
            
            if repair_success:
                print("âœ… Constraints repaired, retrying check...")
                # é‡æ–°æª¢æŸ¥
                sat_result, info = check_case_law_hard(constraints, facts, z3_vars, build_expr)
                if sat_result == "UNSAT":
                    print(f"âœ… Case+Law UNSAT â†’ é•è¦æ¡ˆä¾‹ (Unsat core: {info})")
                    violation = True
                    stats.log_checkpoint("step8_case_law_check", True, "UNSAT")
                    stats.log_checkpoint("step8_violation_detected", True, str(info))
                    stats.log_checkpoint("step8_repair_success", True, "Repair successful")
                elif sat_result == "SAT":
                    print("âŒ Case+Law SAT â†’ ä¿®å¾©å¾Œä» SATï¼Œæ¡ˆä¾‹å¯èƒ½ç„¡é•è¦")
                    violation = False
                    stats.log_checkpoint("step8_case_law_check", True, "SAT")
                    stats.log_checkpoint("step8_violation_detected", False, "SAT after repair")
                    stats.log_checkpoint("step8_repair_success", False, "Repair did not achieve UNSAT")
                    raise RuntimeError("Step 8 failed: No violation detected after repair")
                else:
                    print(f"âŒ Still error after repair: {info}")
                    violation = None
                    stats.log_checkpoint("step8_case_law_check", False, f"REPAIR_FAILED: {info}")
                    stats.log_checkpoint("step8_violation_detected", None, str(info))
                    stats.log_checkpoint("step8_repair_success", False, "Repair failed")
                    raise RuntimeError("Step 8 failed: Repair failed")
            else:
                print("âŒ Constraint repair failed")
                violation = None
                stats.log_checkpoint("step8_violation_detected", None, "REPAIR_FAILED")
                stats.log_checkpoint("step8_repair_success", False, "Repair failed")
                raise RuntimeError("Step 8 failed: Constraint repair failed")
  
        elif sat_result == "UNSAT":
            print(f"âœ… Case+Law UNSAT â†’ é•è¦æ¡ˆä¾‹ (Unsat core: {info})")
            violation = True
            stats.log_checkpoint("step8_case_law_check", True, "UNSAT")
            stats.log_checkpoint("step8_violation_detected", True, str(info))

        elif sat_result == "SAT":
            print("âš ï¸ Case+Law SAT â†’ æ¡ˆä¾‹å¯èƒ½ç„¡é•è¦ï¼Œä½†è³‡æ–™é›†ç‚ºé•è¦æ¡ˆä¾‹ï¼Œå˜—è©¦ä¿®å¾©ä»¥é”æˆ UNSAT")
            stats.log_checkpoint("step8_case_law_check", False, "SAT (unexpected)")
            
            # ğŸ”‘ æ–°çš„ä¿®å¾©ç­–ç•¥
            print("\n" + "="*60)
            print("Step 8.1: SATâ†’UNSAT Repair")
            print("="*60)
            
            repaired_facts, repaired_constraints, repaired_varspecs, repair_success = repair_sat_to_unsat(
                team=team,
                constraints=constraints,
                facts=facts,
                varspecs=varspecs,
                z3_vars=z3_vars,
                build_expr=build_expr,
                case_text=case_text,
                stats=stats
            )
            
            if repair_success:
                print("âœ… SATâ†’UNSAT ä¿®å¾©æˆåŠŸ")
                # æ›´æ–°ä¿®å¾©å¾Œçš„çµæœ
                facts = repaired_facts
                constraints = repaired_constraints
                varspecs = repaired_varspecs
                # é‡æ–°å®£å‘Š z3 è®Šæ•¸ï¼ˆå¦‚æœ varspecs æœ‰æ”¹è®Šï¼‰
                z3_vars = declare_vars(varspecs)
                
                # é‡æ–°æª¢æŸ¥
                sat_result, info = check_case_law_hard(constraints, facts, z3_vars, build_expr)
                print(f"âœ… Final check: {sat_result} - {info}")
                violation = True
                stats.log_checkpoint("step8_case_law_check", True, "UNSAT after repair")
                stats.log_checkpoint("step8_violation_detected", True, str(info))
                stats.log_checkpoint("step8_repair_success", True, "SATâ†’UNSAT repair successful")
            else:
                print("âŒ SATâ†’UNSAT ä¿®å¾©å¤±æ•—")
                violation = False
                stats.log_checkpoint("step8_violation_detected", False, "SAT and repair failed")
                stats.log_checkpoint("step8_repair_success", False, "SATâ†’UNSAT repair failed")
                raise RuntimeError("Step 8 failed: SATâ†’UNSAT repair failed")

        # ğŸ”‘ å¦‚æœæ²’æœ‰æª¢æ¸¬åˆ°é•è¦ï¼Œraise ç•°å¸¸
        if violation is not True:
            raise RuntimeError("Step 8 failed: No violation detected")
        
         # === Step 9: Z3 Optimize ===
        print("\n" + "="*60)
        print("Step 9: Z3 Optimize")
        print("="*60)
        ok, model = z3_optimize_case(constraints, facts, z3_vars, build_expr)
        if ok:
            print(f"âœ… Optimization success for {case_id}")
            print(f"\nğŸ“Š Model (filtered):")

            model_lines = []
            for d in model.decls():
                name = d.name()
                if ":" in name:  
                    continue
                val = model[d]
                model_lines.append(f"{name} = {val}")
                print(f"   {name} = {val}")

            # ğŸ”‘ å„²å­˜ä¹¾æ·¨ç‰ˆæœ¬åˆ°æª”æ¡ˆ
            model_path = OUT / f"{case_id}.model.txt"
            model_path.write_text("\n".join(model_lines), encoding="utf-8")

            print(f"âœ… Model saved to: {model_path}")

            
            stats.log_checkpoint("step9_z3_optimize", True, "success")
            stats.mark_success()
            # ğŸ”‘ åŒ¯å‡ºç‚º SMT2 æ ¼å¼
            print("\n" + "="*60)
            print("Step 10: Export to SMT2")
            print("="*60)
            try:
                smt2_path = export_to_smt2(
                    case_id=case_id,
                    constraints=constraints,
                    varspecs=varspecs,
                    facts=facts,
                    z3_vars=z3_vars,
                    build_expr=build_expr,
                    output_dir=OUT
                )
                print(f"âœ… SMT2 exported successfully")
                print(f"   You can run: z3 {smt2_path}")
            except Exception as e:
                print(f"âš ï¸ SMT2 export failed: {e}")
        else:
            print(f"âš ï¸ Optimization failed for {case_id}: {model}")
            stats.log_checkpoint("step9_z3_optimize", False, str(model))
            stats.mark_failure(model)

        log_path = OUT / f"{case_id}.log"
        with open(log_path, "w", encoding="utf-8") as f:
            f.write(log_buffer.getvalue())

        print(f"\nğŸ“ Log saved to: {log_path}")
    
        # å„²å­˜çµæœ
        save_results(case_id, constraints, varspecs, facts, stats)
   
        return {
            "constraints": constraints,
            "varspecs": varspecs,
            "facts": facts,
            "stats": stats
        }

    except Exception as e:
        print(f"âŒ Pipeline failed for {case_id}: {e}")
        stats.mark_failure(e)
        # å³ä½¿å¤±æ•—ä¹Ÿè¦å„²å­˜å·²æœ‰çš„è³‡æ–™
        try:
            save_results(case_id, constraints if 'constraints' in locals() else [], 
                        varspecs if 'varspecs' in locals() else [], 
                        facts if 'facts' in locals() else {}, 
                        stats)
        except:
            pass
        raise


def repair_loop_with_rounds_with_stats(team, constraints, varspecs, build_expr, z3_vars, stats, max_rounds=3):
    """
    åŒ…è£ repair_loop_with_roundsï¼Œé¡å¤–ç´€éŒ„çµ±è¨ˆè³‡æ–™
    """
    result = repair_loop_with_rounds(team, constraints, varspecs, build_expr, z3_vars, max_rounds)
    
    # ğŸ”‘ ç´€éŒ„ä¿®å¾©æ¬¡æ•¸
    _, _, ok, rounds, _ = result
    for _ in range(rounds):
        stats.increment_repair()
    
    return result


def main(failed_indices=None):
    
    team = build_team(llm_config)
    df = pd.read_csv(DATA)
    all_stats = []

    for idx, row in df.iterrows():
        if failed_indices is not None and idx not in failed_indices:
            continue  
        case_id = f"case_{idx}"
        case_text = str(row["æ³•å¾‹æ¡ˆä¾‹"])
        statute_text = str(row["ç›¸é—œæ³•æ¢"])

        print(f"\n{'='*80}")
        print(f"{'='*80}")
        print(f"=== Running {case_id} ===")
        print(f"{'='*80}")
        print(f"{'='*80}")

        try:
            result = run_pipeline(team, case_id, case_text, statute_text)
            all_stats.append(result["stats"].to_summary_dict())
            print(f"\nâœ… {case_id} completed successfully")
            
        except Exception as e:
            print(f"\nâŒ {case_id} failed: {e}")
            # å³ä½¿å¤±æ•—ä¹Ÿè¦ç´€éŒ„çµ±è¨ˆ
            failed_stats = PipelineStats(case_id)
            failed_stats.mark_failure(e)
            all_stats.append(failed_stats.to_summary_dict())

    # === å„²å­˜çµ±è¨ˆ Excel ===
    stats_df = pd.DataFrame(all_stats)
    
    # ğŸ”‘ èª¿æ•´æ¬„ä½é †åºï¼ˆæª¢æŸ¥é»æ¬„ä½æ”¾åœ¨æœ€å¾Œï¼‰
    checkpoint_cols = [col for col in stats_df.columns if col.startswith("step")]
    base_cols = [
        "case_id",
        "success",
        "total_time_sec",
        "repair_attempts",
        "total_agent_calls",
        "total_input_tokens",
        "total_output_tokens",
        "total_tokens",
        "total_cost_usd",
        "error_message",
        "timestamp"
    ]
    column_order = base_cols + checkpoint_cols
    stats_df = stats_df[column_order]
    
    # å„²å­˜åˆ° Excel
    excel_path = OUT / "pipeline_statisticsv2.xlsx"
    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
        # Sheet 1: æ‘˜è¦çµ±è¨ˆ
        stats_df.to_excel(writer, sheet_name='Summary', index=False)
        
        # Sheet 2: å½™ç¸½çµ±è¨ˆ
        summary_data = {
            "Total Cases": len(all_stats),
            "Success Cases": stats_df["success"].sum(),
            "Failed Cases": (~stats_df["success"]).sum(),
            "Success Rate": f"{stats_df['success'].mean()*100:.2f}%",
            "Avg Time (sec)": stats_df["total_time_sec"].mean(),
            "Avg Repair Attempts": stats_df["repair_attempts"].mean(),
            "Total Tokens": stats_df["total_tokens"].sum(),
            "Total Cost (USD)": stats_df["total_cost_usd"].sum()
        }
        summary_df = pd.DataFrame([summary_data])
        summary_df.to_excel(writer, sheet_name='Overall', index=False)
        
        # ğŸ”‘ Sheet 3: æª¢æŸ¥é»çµ±è¨ˆ
        checkpoint_stats = {}
        for col in checkpoint_cols:
            pass_count = (stats_df[col] == "PASS").sum()
            fail_count = (stats_df[col] == "FAIL").sum()
            skip_count = (stats_df[col] == "SKIP").sum()
            not_run_count = (stats_df[col] == "NOT_RUN").sum()
            
            checkpoint_stats[col] = {
                "PASS": pass_count,
                "FAIL": fail_count,
                "SKIP": skip_count,
                "NOT_RUN": not_run_count,
                "Pass Rate": f"{(pass_count / len(stats_df) * 100):.2f}%" if len(stats_df) > 0 else "0%"
            }
        
        checkpoint_df = pd.DataFrame(checkpoint_stats).T
        checkpoint_df.to_excel(writer, sheet_name='Checkpoints')
    
    print(f"\n{'='*60}")
    print(f"=== Pipeline Completed ===")
    print(f"{'='*60}")
    print(f"Total Cases: {len(all_stats)}")
    print(f"Success: {stats_df['success'].sum()}")
    print(f"Failed: {(~stats_df['success']).sum()}")
    print(f"Success Rate: {stats_df['success'].mean()*100:.2f}%")
    print(f"Avg Time: {stats_df['total_time_sec'].mean():.2f} sec")
    print(f"Total Cost: ${stats_df['total_cost_usd'].sum():.6f}")
    print(f"\nğŸ“Š Statistics saved to: {excel_path}")


if __name__ == "__main__":
    fail_list_path = [0]
    main(failed_indices=fail_list_path)