# ========================================
# UI Compliance - Ollama 環境配置
# ========================================
#
# 使用本文件配置 Ollama 部署
# 複製為 .env 並修改相應的值

# ===== Ollama 配置 =====
# 啟用 Ollama 模式（true/false）
USE_OLLAMA=true

# Ollama 模型選擇
# 推薦選項:
#   - llama3.2:1b (1.3GB) - 超輕量，推薦開始用
#   - mistral (4.1GB) - 快速，平衡性能
#   - llama2 (3.8GB) - 通用模型
#   - neural-chat (4.1GB) - 對話優化
#   - dolphin-mixtral (26GB) - 高質量（需要更多資源）
OLLAMA_MODEL=llama3.2:1b

# Ollama 服務地址
# ⚠️ 重要：不要添加 /v1 前綴，應用會自動添加
# 本地: http://localhost:11434
# 遠端: http://192.168.1.100:11434
OLLAMA_BASE_URL=http://localhost:11434

# ===== OpenAI 配置（當 USE_OLLAMA=false 時使用）=====
# OpenAI API Key
OPENAI_API_KEY=

# OpenAI 模型選擇
OPENAI_MODEL=gpt-4.1-mini

# ===== 其他配置 =====
# 日誌級別 (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Chainlit 埠口
CHAINLIT_PORT=8000

# 向量搜索配置
VECTOR_DB_PATH=./chroma_db
COLLECTION_NAME=legal_cases_v2024

# ===== 進階配置 =====
# Ollama CPU 執行緒數（0=自動）
OLLAMA_NUM_THREAD=0

# Ollama 並行請求數
OLLAMA_NUM_PARALLEL=1

# Ollama 保活時間（單位：分鐘，0=永遠保持加載）
OLLAMA_KEEP_ALIVE=5m

# 禁用 GPU（如果有相容性問題）
# OLLAMA_INTEL_GPU=0
# CUDA_VISIBLE_DEVICES=-1
